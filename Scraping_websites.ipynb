{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8ccd340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object search at 0x00000161e282d4e0>\n"
     ]
    }
   ],
   "source": [
    "import googlesearch    \n",
    "search = googlesearch.search('Katy Perry')    \n",
    "print(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e149de1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.instagram.com/katyperry/?hl=en\n",
      "https://www.facebook.com/katyperry\n",
      "https://en.wikipedia.org/wiki/Katy_Perry\n",
      "https://www.gq.com/story/katy-perry-cover-story-february-2014\n",
      "https://www.facebook.com/katyperry\n",
      "https://en.wikipedia.org/wiki/Katy_Perry\n",
      "https://en.wikipedia.org/wiki/Katy_Perry\n",
      "https://www.gq.com/story/katy-perry-cover-story-february-2014\n",
      "https://en.wikipedia.org/wiki/Katy_Perry\n",
      "https://time.com/4914066/taylor-swift-katy-perry-feud-timeline/\n",
      "https://open.spotify.com/artist/6jJ0s89eD6GaHleKKya26X\n",
      "https://www.britannica.com/biography/Katy-Perry\n"
     ]
    }
   ],
   "source": [
    "for s in search:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a3f9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "tnew = googlesearch.search('solar panel cleaners',num_results=25,advanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8adb863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchResult(url=https://sunedisoninfra.com/blog/5-quick-tips-on-how-to-keep-your-solar-panels-clean/, title=5 Quick Tips On How To Keep Your Solar Panels Clean, description=03-Jul-2021 — )\n",
      "SearchResult(url=https://blueravensolar.com/blog/cleaning-solar-panels/, title=Cleaning solar panels: Is it even necessary?, description=11-Apr-2019 — )\n",
      "SearchResult(url=https://kenbrooksolar.com/price-list/solar-panel-cleaning-system-kit-price-in-india, title=Best price for solar panel cleaning kit in India, description=Just rub the surface of solar panels with cleaning brush and soapy water. It removes the dirt and blockages resting on the surface of the solar ...)\n",
      "SearchResult(url=https://www.solar-panel-cleaners.com/, title=Solar Panel Cleaners: Home, description=Utility Scale Solar Panel Cleaning. Clean Solar Solutions have cleaned millions of solar panels on solar farms across Europe. We provide an option for automated ...)\n",
      "SearchResult(url=https://economictimes.indiatimes.com/small-biz/productline/power-generation/solar-panel-cleaning-services-from-robots-kits-to-water-jet-pressure-heres-all-you-need-to-know/articleshow/69230349.cms, title=Solar panel cleaning services: From robots, kits to water jet ..., description=08-May-2019 — )\n",
      "SearchResult(url=https://taypro.in/, title=Solar Panel Cleaning Machine, Automatic Solar Panel ..., description=We Offer Solar Panel Cleaning Machine, Automatic Solar Panel Cleaning Machine, Robotic Solar Panel Cleaning Machine, Wireless Solar Panel Cleaning Machine, ...)\n",
      "SearchResult(url=https://www.crystalservicesgroup.com.au/services/house-washing/solar-panel-cleaning/, title=Solar Panel Cleaning | Crystal Services Group | SYDNEY, description=Wherever and whenever possible, panels should be cleaned using purified water (PURE WATER SYSTEM – WATER FED POLE) and a soft brush. Panels should not be ...)\n",
      "SearchResult(url=https://us.sunpower.com/home-solar-panel-cleaning-tips-checklist, title=Home Solar Panel Cleaning Tips & Checklist | SunPower, description=What's the Best Way to Clean My Solar Panels? · Hose · Water · Window cleaner or 3% soap‐and‐water solution (optional) · Soft-bristle brush or squeegee (like those ...)\n",
      "SearchResult(url=https://pressureandsteam.com.au/cleaning-services/solar-panel-cleaning/, title=Professional Solar Panel Cleaning Services in Sydney, description=Save money with clean solar panels. For residential or commercial solar panel cleaning services, call Pressure and Steam experts at 02 8007 7205.)\n",
      "SearchResult(url=https://sunedisoninfra.com/blog/5-quick-tips-on-how-to-keep-your-solar-panels-clean/, title=5 Quick Tips On How To Keep Your Solar Panels Clean, description=03-Jul-2021 — )\n",
      "SearchResult(url=https://blueravensolar.com/blog/cleaning-solar-panels/, title=Cleaning solar panels: Is it even necessary?, description=11-Apr-2019 — )\n",
      "SearchResult(url=https://kenbrooksolar.com/price-list/solar-panel-cleaning-system-kit-price-in-india, title=Best price for solar panel cleaning kit in India, description=Just rub the surface of solar panels with cleaning brush and soapy water. It removes the dirt and blockages resting on the surface of the solar ...)\n",
      "SearchResult(url=https://www.solar-panel-cleaners.com/, title=Solar Panel Cleaners: Home, description=Utility Scale Solar Panel Cleaning. Clean Solar Solutions have cleaned millions of solar panels on solar farms across Europe. We provide an option for automated ...)\n",
      "SearchResult(url=https://www.washrite.co.nz/cleaning-service/solar-panel-cleaning-and-washing, title=Solar Panel Cleaning - Wash Rite, description=Wash Rite are experts in cleaning all brands and types of solar panel systems. We always use the most up-to-date techniques when cleaning, which includes using ...)\n",
      "SearchResult(url=https://economictimes.indiatimes.com/small-biz/productline/power-generation/solar-panel-cleaning-services-from-robots-kits-to-water-jet-pressure-heres-all-you-need-to-know/articleshow/69230349.cms, title=Solar panel cleaning services: From robots, kits to water jet ..., description=08-May-2019 — )\n",
      "SearchResult(url=https://taypro.in/, title=Solar Panel Cleaning Machine, Automatic Solar Panel ..., description=We Offer Solar Panel Cleaning Machine, Automatic Solar Panel Cleaning Machine, Robotic Solar Panel Cleaning Machine, Wireless Solar Panel Cleaning Machine, ...)\n",
      "SearchResult(url=https://www.crystalservicesgroup.com.au/services/house-washing/solar-panel-cleaning/, title=Solar Panel Cleaning | Crystal Services Group | SYDNEY, description=Wherever and whenever possible, panels should be cleaned using purified water (PURE WATER SYSTEM – WATER FED POLE) and a soft brush. Panels should not be ...)\n",
      "SearchResult(url=https://us.sunpower.com/home-solar-panel-cleaning-tips-checklist, title=Home Solar Panel Cleaning Tips & Checklist | SunPower, description=What's the Best Way to Clean My Solar Panels? · Hose · Water · Window cleaner or 3% soap‐and‐water solution (optional) · Soft-bristle brush or squeegee (like those ...)\n",
      "SearchResult(url=https://pressureandsteam.com.au/cleaning-services/solar-panel-cleaning/, title=Professional Solar Panel Cleaning Services in Sydney, description=Save money with clean solar panels. For residential or commercial solar panel cleaning services, call Pressure and Steam experts at 02 8007 7205.)\n",
      "SearchResult(url=https://www.solar-panel-cleaners.com/, title=Solar Panel Cleaners: Home, description=Utility Scale Solar Panel Cleaning. Clean Solar Solutions have cleaned millions of solar panels on solar farms across Europe. We provide an option for automated ...)\n",
      "SearchResult(url=https://www.crystalservicesgroup.com.au/services/house-washing/solar-panel-cleaning/, title=Solar Panel Cleaning | Crystal Services Group | SYDNEY, description=Wherever and whenever possible, panels should be cleaned using purified water (PURE WATER SYSTEM – WATER FED POLE) and a soft brush. Panels should not be ...)\n",
      "SearchResult(url=https://us.sunpower.com/home-solar-panel-cleaning-tips-checklist, title=Home Solar Panel Cleaning Tips & Checklist | SunPower, description=What's the Best Way to Clean My Solar Panels? · Hose · Water · Window cleaner or 3% soap‐and‐water solution (optional) · Soft-bristle brush or squeegee (like those ...)\n",
      "SearchResult(url=https://pressureandsteam.com.au/cleaning-services/solar-panel-cleaning/, title=Professional Solar Panel Cleaning Services in Sydney, description=Save money with clean solar panels. For residential or commercial solar panel cleaning services, call Pressure and Steam experts at 02 8007 7205.)\n",
      "SearchResult(url=https://www.crystalservicesgroup.com.au/services/house-washing/solar-panel-cleaning/, title=Solar Panel Cleaning | Crystal Services Group | SYDNEY, description=Wherever and whenever possible, panels should be cleaned using purified water (PURE WATER SYSTEM – WATER FED POLE) and a soft brush. Panels should not be ...)\n",
      "SearchResult(url=https://us.sunpower.com/home-solar-panel-cleaning-tips-checklist, title=Home Solar Panel Cleaning Tips & Checklist | SunPower, description=What's the Best Way to Clean My Solar Panels? · Hose · Water · Window cleaner or 3% soap‐and‐water solution (optional) · Soft-bristle brush or squeegee (like those ...)\n",
      "SearchResult(url=https://pressureandsteam.com.au/cleaning-services/solar-panel-cleaning/, title=Professional Solar Panel Cleaning Services in Sydney, description=Save money with clean solar panels. For residential or commercial solar panel cleaning services, call Pressure and Steam experts at 02 8007 7205.)\n"
     ]
    }
   ],
   "source": [
    "for solar in tnew:\n",
    "    print(solar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afbfd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = list(tnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe951936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchResult(url=http://energy.asu.edu.jo/index.php/r-d/solar-panel-cleaning-system, title=Solar Panel Cleaning System, description=Solar Panel Cleaning Systems · 1- Heliotex technology: Heliotex is an automatic cleaning system that washes and rinses solar panel surfaces. · 2- Electrostatics ...)\n",
      "SearchResult(url=https://sunedisoninfra.com/blog/5-quick-tips-on-how-to-keep-your-solar-panels-clean/, title=5 Quick Tips On How To Keep Your Solar Panels Clean, description=03-Jul-2021 — )\n",
      "SearchResult(url=https://kenbrooksolar.com/price-list/solar-panel-cleaning-system-kit-price-in-india, title=Best price for solar panel cleaning kit in India, description=Just rub the surface of solar panels with cleaning brush and soapy water. It removes the dirt and blockages resting on the surface of the solar ...)\n",
      "SearchResult(url=https://www.solar-panel-cleaners.com/, title=Solar Panel Cleaners: Home, description=Utility Scale Solar Panel Cleaning. Clean Solar Solutions have cleaned millions of solar panels on solar farms across Europe. We provide an option for automated ...)\n",
      "SearchResult(url=https://economictimes.indiatimes.com/small-biz/productline/power-generation/solar-panel-cleaning-services-from-robots-kits-to-water-jet-pressure-heres-all-you-need-to-know/articleshow/69230349.cms, title=Solar panel cleaning services: From robots, kits to water jet ..., description=08-May-2019 — )\n",
      "SearchResult(url=https://taypro.in/, title=Solar Panel Cleaning Machine, Automatic Solar Panel ..., description=We Offer Solar Panel Cleaning Machine, Automatic Solar Panel Cleaning Machine, Robotic Solar Panel Cleaning Machine, Wireless Solar Panel Cleaning Machine, ...)\n",
      "SearchResult(url=https://www.crystalservicesgroup.com.au/services/house-washing/solar-panel-cleaning/, title=Solar Panel Cleaning | Crystal Services Group | SYDNEY, description=Wherever and whenever possible, panels should be cleaned using purified water (PURE WATER SYSTEM – WATER FED POLE) and a soft brush. Panels should not be ...)\n",
      "SearchResult(url=https://pressureandsteam.com.au/cleaning-services/solar-panel-cleaning/, title=Professional Solar Panel Cleaning Services in Sydney, description=Save money with clean solar panels. For residential or commercial solar panel cleaning services, call Pressure and Steam experts at 02 8007 7205.)\n",
      "SearchResult(url=https://us.sunpower.com/home-solar-panel-cleaning-tips-checklist, title=Home Solar Panel Cleaning Tips & Checklist | SunPower, description=What's the Best Way to Clean My Solar Panels? · Hose · Water · Window cleaner or 3% soap‐and‐water solution (optional) · Soft-bristle brush or squeegee (like those ...)\n",
      "SearchResult(url=http://energy.asu.edu.jo/index.php/r-d/solar-panel-cleaning-system, title=Solar Panel Cleaning System, description=Solar Panel Cleaning Systems · 1- Heliotex technology: Heliotex is an automatic cleaning system that washes and rinses solar panel surfaces. · 2- Electrostatics ...)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "while counter < 10:\n",
    "    print(next(tnew))\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54a3b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the stock name:Nidec\n",
      "SearchResult(url=https://auto.economictimes.indiatimes.com/tag/nidec, title=Latest nidec News, Information & Updates - ET Auto, description=ETAuto.com brings latest nidec news, views and updates from all top sources for the Indian Auto industry.)\n",
      "SearchResult(url=https://auto.economictimes.indiatimes.com/tag/nidec, title=Latest nidec News, Information & Updates - ET Auto, description=ETAuto.com brings latest nidec news, views and updates from all top sources for the Indian Auto industry.)\n",
      "SearchResult(url=https://money.cnn.com/quote/forecast/forecast.html?symb=NJ, title=NJDCY - Nidec Corp Forecast - CNNMoney.com - CNN ..., description=Stock Price Forecast ... The 20 analysts offering 12-month price forecasts for Nidec Corp have a median target of 31.92, with a high estimate of 39.37 and a low ...)\n",
      "SearchResult(url=https://financhill.com/stock-forecast/njdcy-stock-prediction, title=Nidec Corp Stock Forecast up to $27.17 - NJDCY Price ..., description=Nidec Corp Stock Forecast · Over the next 52 weeks, Nidec Corp has on average historically risen by 25.5% based on the past 19 years of stock performance. · Nidec ...)\n",
      "SearchResult(url=https://walletinvestor.com/stock-forecast/njdcy-stock-prediction, title=Nidec Stock Forecast: down to 17.675 USD? - NJDCY Stock ..., description=Yes. The Nidec stock price may drop from 18.742 USD to 17.675 USD . The change will be -5.694%. Will NJDCY stock price grow ...)\n",
      "SearchResult(url=https://walletinvestor.com/stock-forecast/nndnf-stock-prediction, title=Nidec Stock Forecast: down to 76.782 USD? - NNDNF Stock ..., description=Yes. The Nidec stock price may drop from 78.450 USD to 76.782 USD . The change will be -2.127%. Will NNDNF stock price grow / rise / go up?)\n",
      "SearchResult(url=https://in.investing.com/equities/nidec-corp-technical, title=Nidec Corp Share Technical Analysis (6594) - Investing.com, description=A summary for the Nidec Corp share. Signals range from Strong Buy, Buy, Neutral, Sell to Strong Sell. It also offers detailed technical analysis based on the ...)\n",
      "SearchResult(url=https://www.tradingview.com/symbols/TSE-6594/technicals/, title=Technical Analysis of NIDEC CORPORATION (TSE:6594), description=A fast and easy way to analyze Japan Stocks. Technical analysis gauges display real-time ratings for the selected timeframes. The summary for NIDEC ...)\n",
      "SearchResult(url=https://www.nidec.com/en/technology/capability/, title=Nidec's Technical Capabilities, description=At Nidec, we utilize original modeling technology and analysis software developed in-house to optimize the design of our fluid dynamic bearings. Fluid Dynamic ...)\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search# stored queries in a list\n",
    "\n",
    "query_list = [\"News\",\"Share price forecast\",\"Technical Analysis\"]# save the company name in a variable  \n",
    "\n",
    "company_name = input(\"Please provide the stock name:\")# iterate through different keywords, search and print  \n",
    "\n",
    "for j in query_list:  \n",
    "   for i in search(company_name+j, lang='en', num_results=2,advanced=True):  \n",
    "      print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60a80744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the company name:Alphabet\n",
      "Please give the appropriate value. 1 for Fundamental Analysis, 2 for News, 3 for Technical Analysis & 4 for Share Price Forecast:1\n",
      "Alphabet Fundamental Analysis:\n",
      " \n",
      "\thttps://abc.xyz/\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "import requests  \n",
    "from lxml.html import fromstring# Link URL Title retriever usin request and formstring  \n",
    "\n",
    "def Link_title(URL):  \n",
    "  x = requests.get(URL)  \n",
    "  tree = fromstring(x.content)  \n",
    "  return tree.findtext('.//title')\n",
    "\n",
    "company_name = input(\"Please provide the company name:\")\n",
    "query = int(input(\"Please give the appropriate value. 1 for Fundamental Analysis, 2 for News, 3 for Technical Analysis & 4 for Share Price Forecast:\"))\n",
    "if query == 1:  \n",
    "  print (company_name+\" \"+\"Fundamental Analysis:\")  \n",
    "  print (\" \")  \n",
    "  for i in search(company_name, num_results=1):  \n",
    "    print (\"\\t\"+i)\n",
    "elif query == 2:  \n",
    "  print (company_name+\" \"+\"News:\")  \n",
    "  print (\" \")  \n",
    "  for i in search(company_name+ 'News', num_results=3):  \n",
    "    print (\"\\t\"+\"#\"+\" \"+Link_title(i))  \n",
    "    print(\"\\t\"+i)  \n",
    "    print(\" \")\n",
    "elif query == 3:  \n",
    "  print (company_name+\" \"+\"Technical Analysis:\")  \n",
    "  print (\" \")  \n",
    "  for i in search(company_name+ 'Technical Analysis', num_results=3):  \n",
    "    print (\"\\t\"+\"#\"+\" \"+Link_title(i))  \n",
    "    print(\"\\t\"+i)  \n",
    "    print(\" \")\n",
    "else:  \n",
    "  print (company_name+\" \"+\"Share Price Forecast:\")  \n",
    "  print (\" \")  \n",
    "  for i in search(company_name+ 'share price forecast',num_results=3):  \n",
    "    print (\"\\t\"+\"#\"+\" \"+Link_title(i))  \n",
    "    print(\"\\t\"+i)  \n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f6fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating the session\n",
    "scrape = requests.Session()\n",
    "#Getting the first URL\n",
    "entry = 'https://www.google.com/search?ie=ISO-8859-1&hl=en-IN&source=hp&biw=&bih=&q=solar+power'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537d6ee",
   "metadata": {},
   "source": [
    "links = tree.xpath('//div/a/@href')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c6580",
   "metadata": {},
   "source": [
    "#used\n",
    "for index, link in enumerate(filter_text):\n",
    "    link_dataframe.loc[index,'Site_heading'] = link.text_content().split('›')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d85807",
   "metadata": {},
   "source": [
    "filter_text = tree.xpath('//div[contains(@class,\"egMi0 kCrYT\")]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9597a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used\n",
    "filter_link = tree.xpath('//div[contains(@class,\"egMi0 kCrYT\")]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "670df69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,link in enumerate(filter_link):\n",
    "    temp = link.get('href').split('=')[1]\n",
    "    link_dataframe.loc[index,'Site_link'] = temp.split('&')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754f759",
   "metadata": {},
   "source": [
    "Regularly I look for information about a particular industry, product, and some concepts. I visit the websites and read the contents in them, make copy of the data into an excel sheet and later collate into a file. \n",
    "\n",
    "I want thinking to automate the data gathering from various websites that come up in the google search. Pseudocode would be something like the following\n",
    "\n",
    "* Get a list of items you want to search, the list can be of same item worded differently \n",
    "\n",
    "* Initialise a request object to Google search with the item in the list\n",
    "\n",
    "* Collect the list of links that come on the top of the google search\n",
    "\n",
    "    + There are  different outcomes possible depending on the words searched.\n",
    "    \n",
    "    Most probably, additional work might be required at this point to get the main links\n",
    "    \n",
    "* Loop through the list of words, and collect the links\n",
    "\n",
    "After collecting the links, \n",
    "\n",
    "* Call each websites \n",
    "\n",
    "* Get the top page completely\n",
    "\n",
    "* store the page corresponding to the website link\n",
    "\n",
    "There could be multiple data types available in the website\n",
    "   + Text\n",
    "       - Headings\n",
    "       - body containing many para\n",
    "       - tables\n",
    "       - list\n",
    "   + Images\n",
    "   + Links\n",
    "   + Videos(can be links too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "603d24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dataset\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "from urllib.parse import unquote\n",
    "from urllib.parse import urljoin\n",
    "from urllib.parse import urlparse\n",
    "from pytube import YouTube\n",
    "from pytube import Channel\n",
    "from pytube import Search\n",
    "from pytube.innertube import InnerTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db93fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "from bs4 import BeautifulSoup \n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b505e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_site(link):\n",
    "    #Initiating the session\n",
    "    link = link.replace(' ','+')\n",
    "    scrape = requests.Session()\n",
    "    #Getting the first URL\n",
    "    entry = 'https://www.google.com/search?ie=ISO-8859-1&hl=en-IN&source=hp&biw=&bih=&q='+link\n",
    "    e = scrape.get(entry)\n",
    "    tree = html.fromstring(e.content)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d966027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the top 10 links in the page\n",
    "def extract_link(tree):    \n",
    "    link = []\n",
    "    text = []\n",
    "    \n",
    "    temp = tree.xpath('//div[@class]/a/@href')[8:17]\n",
    "    if len(temp) > 0:\n",
    "        for t in temp:\n",
    "            if ('q=') in t: # check if there is q= character\n",
    "                link.append(t.split('q=')[1])\n",
    "            else:\n",
    "                link.append(t)\n",
    "    else:\n",
    "        print('no link data')\n",
    "                \n",
    "    heading = tree.xpath('//h3')\n",
    "    if len(heading) > 0:    \n",
    "        for x in heading:\n",
    "            text.append(x.text_content())\n",
    "    else:\n",
    "        print('No heading data')\n",
    "    return link, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b5ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the top 10 raw links in the page\n",
    "def extract_raw(tree):    \n",
    "    link = []\n",
    "    text = []\n",
    "    \n",
    "    temp = tree.xpath('//div[@class]/a/@href')[8:17]\n",
    "    if len(temp) > 0:\n",
    "        for t in temp:\n",
    "            link.append(t)\n",
    "    else:\n",
    "        print('No search data')\n",
    "    heading = tree.xpath('//h3')\n",
    "    if len(heading) > 0:    \n",
    "        for x in heading:\n",
    "            text.append(x.text_content())\n",
    "    else:\n",
    "        print('No heading data')\n",
    "    return link, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f903791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if there is a top list return it\n",
    "def top_list(tree):    \n",
    "    top = []\n",
    "    listing = tree.xpath('//ol/li') \n",
    "    if len(listing) > 0:    \n",
    "        for i in listing:\n",
    "            top.append(i.text_content())\n",
    "    else:\n",
    "        print('No top list')\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b5911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = ['top solar robots', 'top solar cleaners in India','Solar cleaning Robots',\n",
    "               'Working of of Solar Cleaning Robots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fe20c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_new = ['Alphabet Fundamentals', 'Alphabet Analysis','Google Alphabet',\n",
    "               'Deep mind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed9c3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate 3 lists for storing your collection\n",
    "found_link =[]\n",
    "found_text =[]\n",
    "google_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f542f976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No top list\n",
      "No top list\n",
      "No top list\n",
      "No top list\n"
     ]
    }
   ],
   "source": [
    "for words in search_new:\n",
    "    tree = load_site(words) #load the google search, and get tree\n",
    "    #send the tree into extract_link() function\n",
    "    found_link.append(extract_link(tree)[0])\n",
    "    #print('collected links')\n",
    "    found_text.append(extract_link(tree)[1])\n",
    "    #print('collected texts')\n",
    "    #send the tree through top_list() function\n",
    "    google_list.append(top_list(tree))\n",
    "    #print('collected top lists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f0abec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('q=') in found_link[0][1] #Checking if the loop has worked properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b50589f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Check how many links were extracted\n",
    "for extract in found_link:\n",
    "    print(len(extract))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7df61d",
   "metadata": {},
   "source": [
    "Each of these links will open the website, which contain the data that I was talking about...before that, need to ensure there are no duplicate links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26a9452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Links for website scraping\n",
    "scrap_link = []\n",
    "for extract in found_link:\n",
    "    for e in extract:\n",
    "        if e not in scrap_link:\n",
    "            scrap_link.append(e)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebf9837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the links, the dataframe can be created.\n",
    "data_collector = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b6327bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collector['links'] = scrap_link #Sending the links into the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a7929ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collector.loc[:,'website'] = data_collector.links.apply(lambda x: urlparse(x).netloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d71df0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://research.tradeking.com/research/quotes...</td>\n",
       "      <td>research.tradeking.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://research.tradeking.com/research/quotes...</td>\n",
       "      <td>research.tradeking.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://research.tradeking.com/research/quotes...</td>\n",
       "      <td>research.tradeking.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://csimarket.com/stocks/fundamentals_glan...</td>\n",
       "      <td>csimarket.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.domestika.org/en/courses/2621-fund...</td>\n",
       "      <td>www.domestika.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links                 website\n",
       "0  https://research.tradeking.com/research/quotes...  research.tradeking.com\n",
       "1  https://research.tradeking.com/research/quotes...  research.tradeking.com\n",
       "2  https://research.tradeking.com/research/quotes...  research.tradeking.com\n",
       "3  https://csimarket.com/stocks/fundamentals_glan...           csimarket.com\n",
       "4  https://www.domestika.org/en/courses/2621-fund...       www.domestika.org"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bac1fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['research.tradeking.com', 'csimarket.com', 'www.domestika.org',\n",
       "       'www.chartmill.com', 'www.macroaxis.com', 'courseweb.lt.unt.edu',\n",
       "       'groww.in', 'finance.yahoo.com', 'www.assignmenthelper.org',\n",
       "       'strategicmanagementinsight.com', 'seekingalpha.com',\n",
       "       'pestleanalysis.com', 'www.investors.com',\n",
       "       'www.advisorperspectives.com', 'in.investing.com',\n",
       "       'research-methodology.net', 'abc.xyz', 'en.wikipedia.org', '',\n",
       "       'deepmind.com', 't0.gstatic.com', 'www.quantamagazine.org',\n",
       "       'www.theverge.com', 'www.technologyreview.com', 'www.cnbc.com'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collector.website.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51f25e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://research.tradeking.com/research/quotes/fundamentals.asp%3Fmcsymbol%3DGOOGL'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collector.links = data_collector.links.apply(lambda x : x.split('&')[0])\n",
    "data_collector.links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "473fe509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the amazon links to the format chrome can open\n",
    "data_collector.links = data_collector.links.apply(lambda x: unquote(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ac29ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the amazon links to the format chrome can open\n",
    "data_collector.loc[data_collector.website=='www.amazon.in','links'] = data_collector[data_collector.website == 'www.amazon.in'].links.apply(lambda x: unquote(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "252cb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the youtube links to the format chrome can open\n",
    "data_collector.loc[data_collector.website=='www.youtube.com','links'] = data_collector[data_collector.website == 'www.youtube.com'].links.apply(lambda x: unquote(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54fe3c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://seekingalpha.com/symbol/GOOG'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collector.links[12] # we have take out the last part of the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6464773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://research.tradeking.com/research/quotes/fundamentals.asp?mcsymbol=GOOGL'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unquote(data_collector.links[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e87a079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create seperate dataframe for both these websites\n",
    "youtube = data_collector.loc[data_collector.website=='www.youtube.com'].reset_index()\n",
    "amazon = data_collector.loc[data_collector.website=='www.amazon.in'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04b42ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,link in enumerate(youtube.links):\n",
    "    yt = YouTube(link)\n",
    "    youtube.loc[i,'author'] = yt.author\n",
    "    youtube.loc[i,'description'] = yt.description\n",
    "    #youtube.loc[i,'keyword'] = yt.keywords #Need to understand the issue in using this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f2e58f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.in/Solar-Robot-Kit/s?k=Sola...</td>\n",
       "      <td>www.amazon.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.in/Solar-Power-Toys-Kits/b?...</td>\n",
       "      <td>www.amazon.in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links        website\n",
       "1  https://www.amazon.in/Solar-Robot-Kit/s?k=Sola...  www.amazon.in\n",
       "2  https://www.amazon.in/Solar-Power-Toys-Kits/b?...  www.amazon.in"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b25b580",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-89552d6732e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Initiating the Selenium Drivers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mElementNotInteractableException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "#Initiating the Selenium Drivers\n",
    "from selenium import webdriver\n",
    "import time as time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e15ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "600f1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This brings us the tree\n",
    "def selenium_loader(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(link)\n",
    "    driver.maximize_window()\n",
    "    driver.refresh()\n",
    "    time.sleep(5)\n",
    "    html_source = driver.page_source\n",
    "    tree = html.fromstring(html_source)\n",
    "    driver.quit()\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f177dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_links=[]\n",
    "product_prices=[]\n",
    "product_names=[]\n",
    "for i,links in enumerate(amazon.links):\n",
    "    ama_tree = selenium_loader(links)\n",
    "    product_links.append(ama_tree.xpath('//h2[@class]/a/@href'))\n",
    "    product_prices.append(ama_tree.xpath('//span[contains(@class,\"a-price-whole\")]/text()'))\n",
    "    product_names.append(ama_tree.xpath('//h2[@class]/a/span/text()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5414e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_links = []\n",
    "tabs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c24f8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tree = selenium_loader(data_collector.links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5638fd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alphabet Inc ']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heading\n",
    "data_tree.xpath('//h1/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c27fa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Snapshot',\n",
       " 'Charts',\n",
       " 'News',\n",
       " 'Options',\n",
       " 'Earnings',\n",
       " 'Fundamentals',\n",
       " 'Financials',\n",
       " 'Insiders']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tabs\n",
    "data_tree.xpath('//ul/li/a/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34d7d0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://research.tradeking.com/research/quotes/price-quote.asp?mcsymbol=GOOGL',\n",
       " 'https://research.tradeking.com/research/quotes/stock-charts.asp?mcsymbol=GOOGL&default_chart=true',\n",
       " 'https://research.tradeking.com/research/quotes/stock-news.asp?mcsymbol=GOOGL',\n",
       " 'https://research.tradeking.com/research/quotes/options-prices.asp?mcsymbol=GOOGL',\n",
       " 'https://research.tradeking.com/research/quotes/stock-earnings.asp?mcsymbol=GOOGL',\n",
       " 'https://research.tradeking.com/research/quotes/fundamentals.asp?mcsymbol=GOOGL',\n",
       " 'https://research.tradeking.com/research/quotes/stock-financials.asp?mcsymbol=GOOGL',\n",
       " 'https://research.tradeking.com/research/quotes/insiders.asp?mcsymbol=GOOGL']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tabs\n",
    "data_tree.xpath('//ul/li/a/@href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "874177e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$2,656.58', '$2,655.07 ', '$2,657.22 ', '$2,643.70 - 2,678.50', '493.3  K']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tree.xpath('//span[contains(@class,\"quote\")]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8767168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last Price',\n",
       " \"Today's Change\",\n",
       " 'Bid (Size)',\n",
       " 'Ask (Size)',\n",
       " 'Day Low / High',\n",
       " 'Volume']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tree.xpath('//span[@class=\"title\"]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bebf4a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Price / Earnings ',\n",
       " 'Book Value ',\n",
       " 'Earnings Per Share ',\n",
       " 'Price To Sales Ratio ',\n",
       " 'Price To Book Ratio ',\n",
       " 'Price To Tangible Book Ratio ',\n",
       " '7.72',\n",
       " 'Price/Cash Flow Ratio ',\n",
       " 'Price/Free Cash Flow Ratio ',\n",
       " 'Market Capitalization ',\n",
       " '1.7T',\n",
       " 'Float ',\n",
       " 'Shares Outstanding ',\n",
       " 'Short Interest as a % of Float ',\n",
       " '0.75%',\n",
       " 'Shares Held By Institutions ',\n",
       " 'Sales ',\n",
       " 'Gross Margin ',\n",
       " 'Net Profit Margin ',\n",
       " 'EBIT Margin ',\n",
       " 'EBITDA Margin ',\n",
       " 'Operating Margins ',\n",
       " 'Current Ratio ',\n",
       " 'Quick Ratio ',\n",
       " 'Total Debt/Equity Ratio ',\n",
       " '11.33',\n",
       " 'Debt/Common Equity Ratio ',\n",
       " '11.33',\n",
       " 'Return on Equity ',\n",
       " 'Return on Assets ',\n",
       " 'Asset Turnover ',\n",
       " 'Receivables Turnover ',\n",
       " 'Inventory Turnover ',\n",
       " 'EPS Growth Annual ',\n",
       " 'Dividend Yield 5 Year Average ',\n",
       " '0.00%',\n",
       " 'Current Dividend Yield ',\n",
       " '0.00%',\n",
       " 'Current Payout Ratio ']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tree.xpath('//tr/td/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6064ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data = selenium_loader('https://research.tradeking.com/research/quotes/price-quote.asp?mcsymbol=GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "105dffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address',\n",
       " '1600 Amphitheatre Parkway',\n",
       " 'Mountain View, California 94043',\n",
       " 'Phone',\n",
       " '+1.650.253.0000',\n",
       " 'Number of Employees',\n",
       " '98,771',\n",
       " 'Recent SEC Filing',\n",
       " ' ',\n",
       " 'Chief Executive Officer & Director',\n",
       " 'Sundar Pichai',\n",
       " 'Chief Financial Officer & Senior Vice President',\n",
       " 'Ruth M. Porat',\n",
       " 'Chief Accounting Officer & Vice President',\n",
       " \"Amie Thuerner O'Toole\",\n",
       " 'Vice President',\n",
       " 'Cory R. Ondrejka',\n",
       " 'Price Open',\n",
       " '$2,662.98',\n",
       " 'Previous Close',\n",
       " '$2,665.61',\n",
       " '52 Week Range',\n",
       " '$1,996.09 - 3,030.93',\n",
       " 'Market Capitalization',\n",
       " '$801.5  B',\n",
       " 'Shares Outstanding',\n",
       " '300.8  M',\n",
       " 'Sector',\n",
       " 'Industry',\n",
       " 'Next Earnings Announcement',\n",
       " '04/26/2022',\n",
       " 'Call Open Interest (1d)*',\n",
       " '170,815',\n",
       " 'Put Open Interest (1d)*',\n",
       " '150,484',\n",
       " 'Call Volume (1d)*',\n",
       " '21,122',\n",
       " 'Put Volume (1d)*',\n",
       " '12,961',\n",
       " 'Put Call Open Interest Ratio (1d)*',\n",
       " '0.88',\n",
       " 'Put Call Volume Ratio (1d)*',\n",
       " '0.61',\n",
       " 'Price / Earnings',\n",
       " 'N/A',\n",
       " 'Earnings per Share',\n",
       " 'Beta vs. S&P 500',\n",
       " 'Revenue',\n",
       " '$137.0  B',\n",
       " 'Net Profit Margin',\n",
       " 'Return on Equity',\n",
       " 'Buy',\n",
       " 'Overweight',\n",
       " 'Hold',\n",
       " 'Underweight',\n",
       " 'Sell',\n",
       " 'Consensus Recommendation']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data.xpath('//tr/td/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cfc5a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi = selenium_loader(data_collector.links[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aa6c9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = csi.text_content().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f97928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = []\n",
    "for text in temp:\n",
    "    if text != '':\n",
    "        dat.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c5879cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in dat:\n",
    "    if text == '':\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801dac8a",
   "metadata": {},
   "source": [
    "Starting to work on the youtube scraping project...\n",
    "\n",
    "The videos in the youtube are all kept inside the channel. So any channel will have lot of videos under them and their URL can be taken out. Then the URL can be used to collect the description, likes and other details.\n",
    "\n",
    "Channels \n",
    "\n",
    "    Videos will have links\n",
    "\n",
    "        Will have description, comments, reviews etc\n",
    "        Also will have individual tracks for audio and video\n",
    "\n",
    "\n",
    "Idea is to simply scarpe the top page of youtube for channels, then drill down from there into each of channels and collect the information shown below.\n",
    "\n",
    "Channel   Video Name Desciption likes comments genere keywords views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0feee238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let me start with the favorite channel that I usually listen... \n",
    "c = Channel('https://www.youtube.com/c/MusicLabChill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcea8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelData(link):\n",
    "    cha = Channel(link) #instantiate the channel\n",
    "    data = cha.video_urls #get the list of video links\n",
    "    return data #return the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e14f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chill_list = channelData('https://www.youtube.com/c/MusicLabChill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bca423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid_data(link):\n",
    "    vid_t = YouTube(link)\n",
    "    keys = ','.join(vid_t.keywords)\n",
    "    cha = Channel(vid_t.channel_url)\n",
    "    data = {'Author':vid_t.author,'title':vid_t.title, 'Age_restriction':vid_t.age_restricted,'description':vid_t.description,\n",
    "                'keywords':keys, 'length':vid_t.length,'publish_date':vid_t.publish_date,'views':vid_t.views,'about':cha.about_url}\n",
    "    vid_df = pd.DataFrame(data,index=[0])\n",
    "    return vid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f2ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_collector = pd.DataFrame()\n",
    "for link in chill_list:\n",
    "    c_data = get_vid_data(link)\n",
    "    vid_collector = vid_collector.append(c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4724f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_collector(linklist):\n",
    "    vid_collector = pd.DataFrame()\n",
    "    for link in linklist:\n",
    "        c_data = get_vid_data(link)\n",
    "        vid_collector = vid_collector.append(c_data)\n",
    "    return vid_collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6445f2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_collector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a3c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seems there is a api key that needs to provided. It might kickin anytime...\n",
    "c.yt_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38fe7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dload_vid(link):\n",
    "    vid = YouTube(link)\n",
    "    stream = vid.streams\n",
    "    get_vid = stream.get_highest_resolution()\n",
    "    get_vid.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38fe7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dload_aud(link):\n",
    "    vid = YouTube(link)\n",
    "    stream = vid.streams\n",
    "    get_aud = stream.get_by_itag(140)\n",
    "    get_aud.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b115d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the channels using the search option of youtube\n",
    "search = Search('Using Python to scrape')\n",
    "live_res = search.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eee36f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['web scraping weather data python',\n",
       " 'web scraping amazon reviews',\n",
       " 'python web scraping tutorial',\n",
       " 'python scrapy',\n",
       " 'beautiful soup poem',\n",
       " 'web scraping amazon price',\n",
       " 'beautiful soup song',\n",
       " 'install beautifulsoup python windows',\n",
       " 'web scraping c#',\n",
       " 'web scraper',\n",
       " 'web scraping python selenium',\n",
       " 'web scraping python beautifulsoup']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.completion_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8514b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cea6ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "yout = load_site('https://www.youtube.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a93fd24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Books', 'Videos', 'News', 'Next >', 'Settings', 'Privacy', 'Terms']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout.xpath('//a[@class]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a93fd24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout.xpath('//a[contains(@class,\"yt-simple-endpoint\")]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9fe983f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here',\n",
       " 'Books',\n",
       " 'Videos',\n",
       " 'News',\n",
       " 'Images',\n",
       " 'Maps',\n",
       " 'Shopping',\n",
       " 'Search tools',\n",
       " 'Next >',\n",
       " 'Learn more',\n",
       " 'Sign in',\n",
       " 'Settings',\n",
       " 'Privacy',\n",
       " 'Terms']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yout.xpath('//div/a/t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba5754a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b60effbf831f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe_collector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msearch_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-cf395ed7b469>\u001b[0m in \u001b[0;36mdataframe_collector\u001b[1;34m(linklist)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mvid_collector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinklist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_vid_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mvid_collector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvid_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvid_collector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-0f89221436c4>\u001b[0m in \u001b[0;36mget_vid_data\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vid_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mvid_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYouTube\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChannel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     data = {'Author':vid_t.author,'title':vid_t.title, 'Age_restriction':vid_t.age_restricted,'description':vid_t.description,\n",
      "\u001b[1;32mD:\\portablre\\WPy64-37100\\pypy3.7-v7.3.5-win64\\site-packages\\pytube\\__main__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url, on_progress_callback, on_complete_callback, proxies, use_oauth, allow_oauth_cache)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# video_id part of /watch?v=<video_id>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"https://youtube.com/watch?v={self.video_id}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\portablre\\WPy64-37100\\pypy3.7-v7.3.5-win64\\site-packages\\pytube\\extract.py\u001b[0m in \u001b[0;36mvideo_id\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mYouTube\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \"\"\"\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mregex_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\portablre\\WPy64-37100\\pypy3.7-v7.3.5-win64\\site-packages\\pytube\\helpers.py\u001b[0m in \u001b[0;36mregex_search\u001b[1;34m(pattern, string, group)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \"\"\"\n\u001b[0;32m    126\u001b[0m     \u001b[0mregex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRegexMatchError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaller\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"regex_search\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "search_df = dataframe_collector(search.results)\n",
    "search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1546e855",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-48cc3477fbc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for video in search.get_next_results():\n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce11a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24919bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
